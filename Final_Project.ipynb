{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qSfK3TzzOeBK"
   },
   "source": [
    "# Fundamentals of Data Science\n",
    "Winter Semester 2021\n",
    "\n",
    "## Prof. Francesco Pinto, Prof. Vito Collica, Prof. Simone Chieppa, Prof. Matteo Basile, Prof. Giovanni Montobbio\n",
    "<pinto.1871045@studenti.uniroma1.it>, <collica.2011212@studenti.uniroma1.it>, <chieppa.1846140@studenti.uniroma1.it>, <basile.1760927@studenti.uniroma1.it>, <montobbio.1845035@studenti.uniroma1.it>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0G_LPstI3uF6"
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "## Project part 1: Regression\n",
    "\n",
    "### Code and Theory \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_R7KkUpP3uF4"
   },
   "source": [
    "## Notation\n",
    "\n",
    "- $x^i$ is the $i^{th}$ feature vector\n",
    "- $y^i$ is the expected outcome for the $i^{th}$ training example\n",
    "- $m$ is the number of training examples\n",
    "- $n$ is the number of features\n",
    "- $\\theta$ is the set of parameters learned by the model\n",
    "- $\\hat{y}$ is the estimation of the quality of the sample according to the model\n",
    "\n",
    "Let's start by setting up our Python environment and importing the required libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "skGOzNBb3uF4"
   },
   "outputs": [],
   "source": [
    "import numpy as np # imports a fast numerical programming library\n",
    "import scipy as sp # imports stats functions, amongst other things\n",
    "import pandas as pd # lets us handle data as dataframes\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import timeit # Used to measure execution time\n",
    "import os # Used to assess the number of CPUs of the system\n",
    "from multiprocessing import Pool # Used to parallelize the tests\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "NUM_CORES = max(os.cpu_count()-2, 2)\n",
    "# Uncomment to force a specific number of cores\n",
    "#NUM_CORES = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ffcP6hxn3uF7"
   },
   "source": [
    "## 1.a - Required equations for linear regression\n",
    "\n",
    "### Prediction\n",
    "\n",
    "*   $\\hat{y}=\\theta^Tx$\n",
    "\n",
    "### Likelihood\n",
    "\n",
    "We assume a gaussian distribution for the prediction error:\n",
    "\n",
    "*   $y^{(i)}=\\theta^Tx^{(i)}+\\varepsilon^{(i)}$\n",
    "\n",
    "Where $\\varepsilon$ considers all the unmodeled effects, such as random noise  \n",
    "\n",
    "We also assume that $\\varepsilon^{(i)}$ are independent and identically distributed\n",
    "\n",
    "This allows to write the probability distribution of the output given $\\theta$ as:\n",
    "\n",
    "*   $P(y^{(i)}|x^{(i)};\\theta)=\\frac{1}{\\sqrt{2\\pi}\\sigma}exp(-\\frac{(y^{(i)}-\\theta^Tx^{(i)})^2}{2\\sigma^2})$\n",
    "\n",
    "The likelihood function is a measure that explains how well the model fits the data, in this case it varies with the learned $\\theta$ values and is computed in the following way:\n",
    "*   $L(\\theta)=P(y|x;\\theta)=\\prod_{i=1}^m{P(y^{(i)}|x^{(i)};\\theta)}=\\prod_{i=1}^m{\\frac{1}{\\sqrt{2\\pi}\\sigma}exp(-\\frac{(y^{(i)}-\\theta^Tx^{(i)})^2}{2\\sigma^2})}$\n",
    "\n",
    "### log likelihood\n",
    "\n",
    "*   $l(\\theta)=log(L(\\theta))=log(\\prod_{i=1}^m{\\frac{1}{\\sqrt{2\\pi}\\sigma}exp(-\\frac{(y^{(i)}-\\theta^Tx^{(i)})^2}{2\\sigma^2})})=\\sum_{i=1}^m{log({\\frac{1}{\\sqrt{2\\pi}\\sigma}})exp(-\\frac{(y^{(i)}-\\theta^Tx^{(i)})^2}{2\\sigma^2})}=\\sum_{i=1}^m{[log({\\frac{1}{\\sqrt{2\\pi}\\sigma}})+(-\\frac{(y^{(i)}-\\theta^Tx^{(i)})^2}{2\\sigma^2})]}=mlog({\\frac{1}{\\sqrt{2\\pi}\\sigma}})+\\sum_{i=1}^m(-\\frac{(y^{(i)}-\\theta^Tx^{(i)})^2}{2\\sigma^2})$\n",
    "\n",
    "Our objective is performing MLE (Maximum Likelihood Estimation), maximizing the value of the log likelihood with respect to $\\theta$, for that purpose we can ignore $mlog({\\frac{1}{\\sqrt{2\\pi}\\sigma}})$, and in $\\sum_{i=1}^m(-\\frac{(y^{(i)}-\\theta^Tx^{(i)})^2}{2\\sigma^2})$ we can ignore the constant $\\frac{1}{\\sigma^2}$ (we keep $\\frac{1}{2}$ as it makes the equation of the gradient cleaner):\n",
    "\n",
    "$argmax_\\theta(l(\\theta))=argmax_\\theta(mlog({\\frac{1}{\\sqrt{2\\pi}\\sigma}})+\\sum_{i=1}^m(-\\frac{(y^{(i)}-\\theta^Tx^{(i)})^2}{2\\sigma^2}))\\approx argmax_\\theta(\\frac{1}{2}\\sum_{i=1}^m(-(y^{(i)}-\\theta^Tx^{(i)})^2))=argmin_\\theta(\\frac{1}{2}\\sum_{i=1}^m((y^{(i)}-\\theta^Tx^{(i)})^2))$\n",
    "\n",
    "Which we are gonna minimize through gradient descent.\n",
    "\n",
    "### Gradient of the log likelihood function\n",
    "\n",
    "$\\frac{\\delta}{\\delta\\theta_j}\\frac{1}{2}\\sum_{i=1}^m(y^{(i)}-\\theta^Tx^{(i)})^2=\\sum_{i=1}^{m}(y^{(i)}-\\theta^Tx^{(i)})\\cdot (-x_j^{(i)})$\n",
    "\n",
    "### Gradient descent update rule\n",
    "\n",
    "$\\theta_j =\\theta_j-\\alpha \\frac{\\delta}{\\delta \\theta_j}l(\\theta)= \\theta_j-\\alpha \\sum_{i=1}^{m}(y^{(i)}-\\theta^Tx^{(i)})\\cdot (-x_j^{(i)})$\n",
    "\n",
    "Where $\\alpha$ is the learning rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rbRCfu6u3uF9"
   },
   "source": [
    "#### Implementation of linear regression with Gradient descent\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "0dn3vB4QbqBz"
   },
   "outputs": [],
   "source": [
    "def load_dataset(filename):\n",
    "  #LOAD THE DATASET\n",
    "  dataset = pd.read_csv(filename,sep =';')\n",
    "  df = pd.DataFrame(dataset)\n",
    "  return np.array(df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "eX-YzL1Ni_L9"
   },
   "outputs": [],
   "source": [
    "def divide_Xy(database):\n",
    "  #DIVIDE THE ARRAY IN X AND Y\n",
    "  y = database[:,-1]\n",
    "  X = np.delete(database, -1, 1)\n",
    "  return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "GemsRnRZQ-P1"
   },
   "outputs": [],
   "source": [
    "def divide_train_test(dataset):\n",
    "  #DIVIDE TRAIN AND TEST SET\n",
    "  np.random.seed(0)\n",
    "  np.random.shuffle(dataset) #shuffled dataset\n",
    "  train = dataset[0:int(len(dataset)*0.833)]\n",
    "  test = dataset[int(len(dataset)*0.833):]\n",
    "  return train, test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "r-kD3ARMWsmc"
   },
   "outputs": [],
   "source": [
    "def divide_folds(X):\n",
    "  #KFOLD\n",
    "  result = []\n",
    "  kfold = KFold(5, shuffle=True, random_state=0)\n",
    "  for train,dev in kfold.split(X):\n",
    "    X_train, X_dev = X[train], X[dev]\n",
    "    result.append((X_train,X_dev))\n",
    "  return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iyv6B-sdm4KR"
   },
   "source": [
    "### Define the core functions for the algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "ZhlHmIHI3uGA"
   },
   "outputs": [],
   "source": [
    "def loss_function(theta,features,target):\n",
    "    '''\n",
    "    Function to compute the loss of theta according to data x and label y\n",
    "    \n",
    "    Input:\n",
    "    theta: it's the model parameter matrix.\n",
    "    features: it's the input data matrix. The shape is (N, H)\n",
    "    target: the label array\n",
    "    \n",
    "    Output:\n",
    "    loss: the loss of theta according to data x and label y\n",
    "    '''\n",
    "\n",
    "    # First of all we compute the predictions for the current values of theta \n",
    "    predictions = np.dot(features, theta)\n",
    "    \n",
    "    # In the steps below we compute the loss function \n",
    "    loss = 0\n",
    "\n",
    "    for i in range(len(features)): \n",
    "      loss += 0.5*((target[i] - predictions[i])**2)\n",
    "    \n",
    "    # Finally normalize the loss\n",
    "    loss = loss/len(features)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def predictions(features, theta):\n",
    "    '''\n",
    "    Function to compute the predictions for the input features\n",
    "    \n",
    "    Input:\n",
    "    theta: it's the model parameter matrix.\n",
    "    features: it's the input data matrix. The shape is (N, H)\n",
    "    \n",
    "    Output:\n",
    "    preds: the predictions of the input features\n",
    "    '''\n",
    "\n",
    "\n",
    "    # Dot product between theta and the input data\n",
    "    preds = np.dot(features, theta)      \n",
    "    return preds\n",
    "\n",
    "\n",
    "def update_theta(theta, target, preds, features, lr):\n",
    "    '''\n",
    "    Function to compute the gradient of the loss\n",
    "    and then return the updated weights\n",
    "\n",
    "    Input:\n",
    "    theta: the model parameter matrix.\n",
    "    target: the label array\n",
    "    preds: the predictions of the input features\n",
    "    features: it's the input data matrix. The shape is (N, H)\n",
    "    lr: the learning rate\n",
    "    \n",
    "    Output:\n",
    "    theta: the updated model parameter matrix.\n",
    "    '''\n",
    "\n",
    "    #sum((yi-preds_i)*xij)\n",
    "    for j in range(len(theta)):\n",
    "      gradient = 0\n",
    "      for i in range(len(features)):\n",
    "        # Gradient equation\n",
    "        gradient -= (target[i]-preds[i])*features[i][j]\n",
    "      # Normalize the gradient\n",
    "      gradient = gradient/len(features)\n",
    "      # Update the theta using the gradient computed before\n",
    "      theta[j]=theta[j]-lr*gradient\n",
    "    return theta\n",
    "\n",
    "def gradient_descent(theta, features, target, lr, num_steps):\n",
    "    '''\n",
    "    Function to execute the gradient descent algorithm\n",
    "\n",
    "    Input:\n",
    "    theta: the model parameter matrix.\n",
    "    target: the label array\n",
    "    num_steps: the number of iterations \n",
    "    features: the input data matrix. The shape is (N, H)\n",
    "    lr: the learning rate\n",
    "    \n",
    "    Output:\n",
    "    theta: the final model parameter matrix.\n",
    "    loss_history: the values of the loss function during the process\n",
    "    '''\n",
    "\n",
    "    loss_history = np.zeros(num_steps)\n",
    "    \n",
    "    for i in range(num_steps):\n",
    "      # Compute the sigmoid \n",
    "      preds = predictions(features, theta)\n",
    "      # Perform Gradient Ascent\n",
    "      theta = update_theta(theta, target, preds, features, lr)\n",
    "      # Save the value of the log_likelihood for every step\n",
    "      loss_history[i]=loss_function(theta,features,target)\n",
    "      \n",
    "    return theta, loss_history\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "55mr8J5d3uGB"
   },
   "source": [
    "Let's now apply the function gradient_ascent and print the final theta as well as theta_history "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Rh-cy3XX3uGK"
   },
   "outputs": [],
   "source": [
    "def compute_accuracy(y_pred, y_true, T):\n",
    "  sum = 0\n",
    "  for i in range(len(y_pred)):\n",
    "    # Check if predicted value is within tolerance distance  the ground truth\n",
    "    if y_pred[i]-T <= y_true[i] <= y_pred[i]+T:       \n",
    "      sum +=1\n",
    "  # Normalize the sum to compute the accuracy\n",
    "  accuracy = sum/len(y_true)\n",
    "  return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "kZPZLWLz3uGJ"
   },
   "outputs": [],
   "source": [
    "# For each folds combination train the model and compute the metrics \n",
    "def run_folds_mr(folds, n_iter, alpha, tolerances):\n",
    "  theta_finals = []\n",
    "  confusion_matrices = []\n",
    "  loss_histories = []\n",
    "  ILMIOPIPO = []\n",
    "  resultsmie = {}\n",
    "  for T in tolerances:\n",
    "    # dict(Tolerance: [Accuracies, Precisions])         \n",
    "    resultsmie[T] = [[], []]\n",
    "  for fold in folds:\n",
    "    train = fold[0]\n",
    "    dev = fold[1]\n",
    "    train_X, train_y = divide_Xy(train)\n",
    "    dev_X, dev_y = divide_Xy(dev)\n",
    "\n",
    "    # Cast output values to int\n",
    "    train_y = train_y.astype(int)\n",
    "\n",
    "    # Train the model\n",
    "    theta0 = np.zeros(train_X.shape[1])\n",
    "    theta_final, loss_history = gradient_descent(theta0, train_X, train_y, alpha, n_iter) \n",
    "    loss_histories.append(loss_history)\n",
    "    theta_finals.append(theta_final) \n",
    "\n",
    "    # This is the same as T=0.5 and is used for the confusion matrix\n",
    "    # TODO\n",
    "\n",
    "    y_pred = predictions(dev_X, theta_final)\n",
    "    y_true = dev_y.astype(int)\n",
    "    for T in tolerances:\n",
    "      # Accuracy for the tolerance T in the current fold\n",
    "      resultsmie[T][0].append(compute_accuracy(y_pred,y_true, T))\n",
    "      classes = np.unique(y_true)\n",
    "      for i in classes:\n",
    "        # Confusion matrix for individual class i in the current fold\n",
    "        new_y_pred = convert_to_binary(y_pred, i, T)\n",
    "        new_y_true = convert_to_binary(y_true, i, T)\n",
    "        cm = confusion_matrix(new_y_true, new_y_pred)\n",
    "        # Precisions for the tolerance T in the current fold\n",
    "        if (cm[1][1] + cm[0][1]) == 0:\n",
    "          precision = 0\n",
    "        else:\n",
    "          precision = cm[1][1] / (cm[1][1] + cm[0][1])\n",
    "        resultsmie[T][1].append(precision)\n",
    "  averaged_accuracies = {}\n",
    "  averaged_precisions = {}\n",
    "  # Average for all folds\n",
    "  for T in tolerances: \n",
    "    averaged_accuracies[T] = sum(resultsmie[T][0]) / len(resultsmie[T][0])\n",
    "    averaged_precisions[T] = sum(resultsmie[T][1]) / len(resultsmie[T][1])\n",
    "  loss_mean = np.mean(loss_histories, axis = 0)\n",
    "  theta_mean = np.mean(theta_finals, axis = 0)\n",
    "  return (theta_mean, loss_mean, averaged_accuracies, averaged_precisions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "O3oTw2M2GC1C"
   },
   "outputs": [],
   "source": [
    "# Turns multivariate classification into binary classification for class i\n",
    "def convert_to_binary(array, i, T):\n",
    "  new_array = []\n",
    "  for elem in array:\n",
    "    if elem-T <= i <= elem+T:\n",
    "      new_array.append(1)\n",
    "    else:\n",
    "      new_array.append(0)\n",
    "  return new_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "DDOiruq-lU4q"
   },
   "outputs": [],
   "source": [
    "# Parallelizes tests for a set of parameters\n",
    "def run_parallelized_test_mr(datasets, lr_values, n_iter_values, tolerances, num_cores):\n",
    "    processes = []\n",
    "    for dataset in datasets:\n",
    "      # load the dataset\n",
    "      loaded_dataset = load_dataset(dataset)\n",
    "      # only need the training set here\n",
    "      train = divide_train_test(loaded_dataset)[0]\n",
    "      for lr in lr_values:\n",
    "          for n_iter in n_iter_values:\n",
    "              # passing the name of the dataset and the dataset itself as a tuple\n",
    "              processes.append([(dataset, train), lr, n_iter, tolerances])\n",
    "    pool = Pool(processes=num_cores)\n",
    "    return pool.map(test_function_mr, processes)\n",
    "\n",
    "def parallelize_predefined_tests_mr(tests, tolerances, num_cores):\n",
    "    processes = []\n",
    "    datasets_dict = {}\n",
    "    for test in tests:\n",
    "        if test[0] not in datasets_dict:\n",
    "            loaded_dataset = load_dataset(test[0])\n",
    "            train = divide_train_test(loaded_dataset)[0]\n",
    "            datasets_dict[test[0]]=train\n",
    "        processes.append([(test[0], datasets_dict[test[0]]), test[1], test[2], tolerances])            \n",
    "    pool = Pool(processes=num_cores)\n",
    "    return pool.map(test_function_mr, processes)\n",
    "\n",
    "# Runs a single test for a (dataset, lr, n_iter, T) tuple\n",
    "def test_function_mr(arguments):\n",
    "\n",
    "  dataset, lr, n_iter, tolerances = arguments\n",
    "\n",
    "  # Log execution time for each test\n",
    "  time_start = timeit.default_timer()\n",
    "\n",
    "  print('running on the dataset ' + str(dataset[0]) + ', lr=' + str(lr) + ', n_iter=' + str(n_iter) + '\\n')\n",
    "\n",
    "  folds = divide_folds(dataset[1])\n",
    "\n",
    "  # Initialize theta0\n",
    "  theta0 = np.zeros(dataset[1].shape[1])\n",
    "\n",
    "  # Run gradient descent\n",
    "  theta_mean, loss_mean, accuracies, precisions = run_folds_mr(folds,  n_iter, lr, tolerances)\n",
    "\n",
    "  # Compute elapsed time and accuracy\n",
    "  time_end = timeit.default_timer()\n",
    "  elapsed_time = time_end-time_start\n",
    "\n",
    "  print('done! dataset=' + str(dataset[0]) + ', lr=' + str(lr) + ', n_iter=' + str(n_iter) + ', elapsed time=' + str(elapsed_time) + ', loss=' + str(loss_mean[-1]) + ', accuracy(T=1)=' + str(accuracies[1]) + ', precision(T=1)=' + str(precisions[1]) + ', accuracy(T=0)=' + str(accuracies[0]) + ', precision(T=0)=' + str(precisions[0]) + '\\n')\n",
    "  \n",
    "  # Return the results\n",
    "  return [(dataset[0], lr, n_iter), elapsed_time, theta_mean, loss_mean, accuracies, precisions]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "ajh8uvxR3uGB",
    "outputId": "22152d17-fbbd-42e2-f02d-8f5353396b25"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running on the dataset winequality-red.csv, lr=5e-05, n_iter=10\n",
      "running on the dataset winequality-red.csv, lr=0.0005, n_iter=10\n",
      "\n",
      "\n",
      "done! dataset=winequality-red.csv, lr=0.0005, n_iter=10, elapsed time=16.12989930799813, loss=3.121896117986139, accuracy(T=1)=0.19765706400833544, precision(T=1)=0.4405961401879748, accuracy(T=0)=0.0, precision(T=0)=0.0\n",
      "\n",
      "done! dataset=winequality-red.csv, lr=5e-05, n_iter=10, elapsed time=16.699103061997448, loss=5.19323592546186, accuracy(T=1)=0.15553490467742387, precision(T=1)=0.4749164016372394, accuracy(T=0)=0.0, precision(T=0)=0.0\n",
      "\n",
      "test complete, elapsed time: 16.848076260997914\n",
      "[[('winequality-red.csv', 5e-05, 10), 16.699103061997448, 5.19323592546186, 0.15553490467742387, 0.4749164016372394, 0.0, 0.0], [('winequality-red.csv', 0.0005, 10), 16.12989930799813, 3.121896117986139, 0.19765706400833544, 0.4405961401879748, 0.0, 0.0]]\n"
     ]
    }
   ],
   "source": [
    "# Tests various possible numbers of samples, values of the learning rate and numbers of iterations\n",
    "\n",
    "# Parameters used to run the tests\n",
    "datasets = ['winequality-red.csv', 'winequality-white.csv']\n",
    "lr_values = [0.0001, 7.5e-05]\n",
    "n_iter_values = [100]\n",
    "tolerances = [x*0.025 for x in range(0,80)]\n",
    "# Times the duration of the batch\n",
    "time_start_test = timeit.default_timer()\n",
    "\n",
    "# Enable predefined tests\n",
    "enable_predefined_tests = True\n",
    "\n",
    "# This is for running custom tests\n",
    "predefined_tests = []\n",
    "# Server Vito\n",
    "predefined_tests.append([('winequality-red.csv', 0.00015, 2000), ('winequality-red.csv', 0.00015, 1000), ('winequality-red.csv', 0.0001, 2000), ('winequality-red.csv', 0.0002, 2000), ('winequality-red.csv', 0.0002, 1000), ('winequality-red.csv', 0.00005, 1000), ('winequality-red.csv', 0.00005, 500), ('winequality-red.csv', 0.00005, 2000), ('winequality-red.csv', 7.5e-05, 1000), ('winequality-red.csv', 7.5e-04, 1000), ('winequality-red.csv', 7.5e-04, 2000), ('winequality-white.csv', 7.5e-05, 2000), ('winequality-white.csv', 6e-05, 1000), ('winequality-white.csv', 0.00001, 1000), ('winequality-white.csv', 0.00001, 2000), ('winequality-red.csv', 0.0001, 3000)])\n",
    "# Mac Francesco\n",
    "predefined_tests.append([('winequality-white.csv', 7.5e-05, 3000), ('winequality-white.csv', 2.5e-05, 4000), ('winequality-red.csv', 7.5e-05, 2000), ('winequality-white.csv', 5e-05, 3000)])\n",
    "# Mac Simone\n",
    "predefined_tests.append([('winequality-red.csv', 0.00005, 4000), ('winequality-white.csv', 5e-05, 2000), ('winequality-white.csv', 6e-05, 2000), ('winequality-white.csv', 0.00001, 3000)])\n",
    "predefined_tests.append([('winequality-red.csv', 0.00005, 10), ('winequality-red.csv', 0.0005, 10)])\n",
    "\n",
    "# Which tests to run\n",
    "test_index = -1\n",
    "\n",
    "# Starts the tests\n",
    "if(enable_predefined_tests):\n",
    "    test_results = parallelize_predefined_tests_mr(predefined_tests[test_index], tolerances, NUM_CORES)\n",
    "else:\n",
    "    test_results = run_parallelized_test_mr(datasets, lr_values, n_iter_values, tolerances, NUM_CORES)\n",
    "\n",
    "time_end_test = timeit.default_timer()\n",
    "test_elapsed_time = time_end_test-time_start_test\n",
    "print('test complete, elapsed time: ' + str(test_elapsed_time))\n",
    "\n",
    "results_file = open('regression_results_' + str(test_index) + '.txt', 'w')\n",
    "# Only considers the last value of the loss function for the results\n",
    "output = []\n",
    "for result in test_results:\n",
    "  #output.append([result[0], result[1], result[3][-1], result[4][1], result[5][1]])\n",
    "  output.append([result[0], result[1], result[3][-1], result[4][1], result[5][1], result[4][0], result[5][0]])\n",
    "  results_file.write(str(result)+'\\n')\n",
    "results_file.close()\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ztw28vX6uQ5e"
   },
   "source": [
    "## Make predictions over the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P_9UCcxKuiGr"
   },
   "outputs": [],
   "source": [
    "def run_final_test(test_X, test_y, theta_final, tolerances):\n",
    "  theta_finals = []\n",
    "  confusion_matrices = []\n",
    "  loss_histories = []\n",
    "  y_pred = predictions(test_X, theta_final)\n",
    "  y_true = test_y.astype(int)\n",
    "  metrics = {}\n",
    "  for T in tolerances:       \n",
    "    metrics[T] = [0, []]\n",
    "    # Accuracy for the tolerance T\n",
    "    metrics[T][0] = compute_accuracy(y_pred,y_true, T)\n",
    "    classes = np.unique(y_true)\n",
    "    for i in classes:\n",
    "      # Confusion matrix for individual class i \n",
    "      new_y_pred = convert_to_binary(y_pred, i, T)\n",
    "      new_y_true = convert_to_binary(y_true, i, T)\n",
    "      cm = confusion_matrix(new_y_true, new_y_pred)\n",
    "      # Precisions for the tolerance T\n",
    "      if (cm[1][1] + cm[0][1]) == 0:\n",
    "        precision = 0\n",
    "      else:\n",
    "        precision = cm[1][1] / (cm[1][1] + cm[0][1])\n",
    "      metrics[T][1].append(precision)\n",
    "    metrics[T][1] = sum(metrics[T][1]) / len(metrics[T][1])\n",
    "  \n",
    "  confusion_final = confusion_matrix(y_true,np.round_(y_pred))\n",
    "  return metrics, confusion_final\n",
    "  \n",
    "\n",
    "def retrieve_theta(results, dataset, lr, num_iter):\n",
    "  data = None\n",
    "  for result in results:\n",
    "    if result[0][0] == dataset and result[0][1] == lr and result[0][2] == num_iter:\n",
    "      data = result\n",
    "      break\n",
    "  if data == None:\n",
    "    return \"result not found\"\n",
    "  return data[2]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VQHAnBceD23S"
   },
   "outputs": [],
   "source": [
    "#TAKE THE TEST SETS\n",
    "white_set = load_dataset(\"winequality-white.csv\")\n",
    "red_set = load_dataset(\"winequality-red.csv\")\n",
    "\n",
    "white_train, white_test = divide_train_test(white_set)\n",
    "white_test_X,white_test_y = divide_Xy(white_test)\n",
    "\n",
    "red_train, red_test = divide_train_test(red_set)\n",
    "red_test_X,red_test_y = divide_Xy(red_test)\n",
    "\n",
    "theta_final_red = retrieve_theta(test_results, \"winequality-red.csv\",0.0001,100)\n",
    "theta_final_white = retrieve_theta(test_results, \"winequality-white.csv\", 7.5e-05, 100)\n",
    "\n",
    "metrics_red, cm_red = run_final_test(red_test_X, red_test_y, theta_final_red, tolerances)\n",
    "metrics_white, cm_white = run_final_test(white_test_X, white_test_y, theta_final_white, tolerances)\n",
    "\n",
    "cm_red, cm_white\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fxVvPkb1lEDt"
   },
   "outputs": [],
   "source": [
    "# Plot the rec curve for specific parameters\n",
    "# Tests for the given parameters have to be run first\n",
    "def rec_curve(metrics,name):\n",
    "  fig,ax = plt.subplots(num=2)\n",
    "  ax.set_ylabel('Accuracy ' + name)\n",
    "  ax.set_xlabel('T')\n",
    "  _=ax.plot([x for x in metrics.keys()],[y[0] for y in metrics.values()],'b.')\n",
    "\n",
    "rec_curve(metrics_red, \"Red\")\n",
    "#rec_curve(metrics_white, \"White\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O1s2H39tBqxO"
   },
   "source": [
    "## Project part 2: Classification "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xi8Cfr4WAqrn"
   },
   "source": [
    "Defining one-hot vectors for the ground truths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Og3q1KcrApdc"
   },
   "outputs": [],
   "source": [
    "import scipy\n",
    "import scipy.sparse\n",
    "import numpy as np\n",
    "\n",
    "def class2OneHot(vec):\n",
    "    out_sparse = scipy.sparse.csr_matrix((np.ones(vec.shape[0]), (vec, np.array(range(vec.shape[0])))))\n",
    "    out_onehot = np.array(out_sparse.todense()).T\n",
    "    return out_onehot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nzG1DzJ50po6"
   },
   "source": [
    "ALGORITHMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dj4xMHxwFCeq"
   },
   "outputs": [],
   "source": [
    "def softmax(theta, X):\n",
    "    softmax = np.zeros((len(X),len(theta[0])))\n",
    "    for i in range(len(X)):\n",
    "      sum = 0\n",
    "      for k in range(len(theta[0])):\n",
    "        # Compute the denominator of the softmax function following the formula written above\n",
    "        sum += np.exp(np.dot(X[i],theta[:,k]))\n",
    "      for j in range(len(theta[0])):\n",
    "        # Compute the numerator of the softmax function following the formula written above\n",
    "        num = np.exp(np.dot(X[i], theta[:,j]))\n",
    "        # Compute the probability dividing the numerator by the denominator\n",
    "        softmax[i,j] = num/sum\n",
    "    return softmax\n",
    "\n",
    "\n",
    "def CELoss(theta, X, y_onehot):\n",
    "\n",
    "    loss = 0\n",
    "    softm = softmax(theta,X)\n",
    "    for i in range(len(y_onehot)):\n",
    "      for k in range(len(y_onehot[0])):\n",
    "        if y_onehot[i][k] == 1:\n",
    "          # Compute the loss where the value of the one hot vector is 1\n",
    "          loss -= np.log(softm[i][k])\n",
    "    return loss\n",
    "\n",
    "\n",
    "def CELoss_jacobian(theta, X, y_onehot):\n",
    "    \n",
    "    # In the steps below we compute the gradient of the cross entropy for every\n",
    "    # Theta and then update the jacobian matrix instead of computing it for one theta at the time\n",
    "    preds = softmax(theta,X)\n",
    "    jacobian = np.zeros((len(theta),len(theta[0])))\n",
    "    for i in range(len(theta[0])):\n",
    "      # For every row in theta initialize the sum as array of zeros\n",
    "      sum = np.zeros(len(X[0]))\n",
    "      for l in range(len(X)):\n",
    "        # Compute the gradient of the cross entropy loss\n",
    "        sum -= X[l]*(y_onehot[l][i] - preds[l][i])\n",
    "      # Normalize the sum\n",
    "      sum = sum/len(X)\n",
    "      for j in range(len(jacobian)):\n",
    "        # Update the value in the jacobian matrix\n",
    "        jacobian[j][i] = sum[j]\n",
    "    return jacobian\n",
    "\n",
    "\n",
    "def gradient_descent(theta, X, y_onehot, alpha=0.01, iterations=100):\n",
    "    \n",
    "    # We initialize an empty array to be filled with loss value after each iteration\n",
    "    loss_history = np.zeros(iterations)\n",
    "    \n",
    "    # With a for loop we compute the steps of GD algo\n",
    "    for it in range(iterations):\n",
    "        # Compute the softmax\n",
    "        preds = softmax(theta, X)\n",
    "        # Compute the jacobian\n",
    "        Jacob = CELoss_jacobian(theta, X, y_onehot)\n",
    "        for j in range(len(theta)):\n",
    "          # Update the value of theta\n",
    "          theta[j]=theta[j]-alpha*Jacob[j]\n",
    "        # Save the value of the cross entropy loss for every iteration\n",
    "        loss_history[it]=CELoss(theta, X, y_onehot)\n",
    "    return theta, loss_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hsnCir1ddI_C"
   },
   "source": [
    "Confusion matrix\n",
    "\n",
    "\n",
    "TP: The actual value and predicted value should be the same. So concerning Setosa class, the value of cell 1 is the TP value.\n",
    "\n",
    "FN: The sum of values of corresponding rows except the TP value\n",
    "\n",
    "FP : The sum of values of corresponding column except the TP value.\n",
    "\n",
    "TN: The sum of values of all columns and row except the values of that class that we are calculating the values for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "75hqdg3zDrI_"
   },
   "outputs": [],
   "source": [
    "# For each folds combination train the model and compute the metrics\n",
    "def run_folds_class(folds, n_iter, alpha, T = 0):\n",
    "\n",
    "  theta_finals = []\n",
    "  confusion_matrices = []\n",
    "  loss_histories = []\n",
    "  for fold in folds:\n",
    "    train = fold[0]\n",
    "    dev = fold[1]\n",
    "    train_X, train_y = divide_Xy(train)\n",
    "    dev_X, dev_y = divide_Xy(dev)\n",
    "    train_y = train_y.astype(int)\n",
    "    train_y_onehot = class2OneHot(train_y)\n",
    "    \n",
    "    np.random.seed(0)\n",
    "    theta0 = np.random.rand(train_X.shape[1], len(train_y_onehot[0]))\n",
    "    \n",
    "    theta_final, loss_history = gradient_descent(theta0, train_X, train_y_onehot, alpha, iterations=n_iter)    #era alpha=0.00001\n",
    "    predictions = softmax(theta_final, dev_X)\n",
    "    y_pred = np.argmax(predictions, axis=-1)\n",
    "    dev_y = dev_y.astype(int)\n",
    "    dev_y_onehot = class2OneHot(dev_y)\n",
    "    y_true = np.argmax(dev_y_onehot, axis=-1)\n",
    "    \n",
    "    cm = confusion_matrix(y_true, y_pred, labels=range(11))\n",
    "    loss_histories.append(loss_history)\n",
    "    theta_finals.append(theta_final)\n",
    "    confusion_matrices.append(cm)\n",
    "\n",
    "  confusion_mean = np.mean(confusion_matrices, axis = 0)\n",
    "  loss_mean = np.mean(loss_histories, axis = 0)\n",
    "  theta_mean = np.mean(theta_finals, axis = 0)\n",
    "  accuracies = []\n",
    "  precisions = []\n",
    "  fp = 0\n",
    "  T = round(T)\n",
    "  for i in range(11):\n",
    "    tp = 0\n",
    "    for t in range(1, T+1):\n",
    "      if (i-t >= 0):\n",
    "        tp += confusion_mean[i,i-t] \n",
    "      if (i+t <= len(confusion_mean[0])-1):\n",
    "        tp += confusion_mean[i,i+t]   \n",
    "    tp += confusion_mean[i,i]\n",
    "    if(T==0):\n",
    "      tp = confusion_mean[i,i]\n",
    "    fp = sum(confusion_mean[:,i]) - confusion_mean[i,i]\n",
    "    fn = sum(confusion_mean[i]) - tp\n",
    "    tn = sum(sum(confusion_mean)) - tp - fp - fn\n",
    "    accuracies.append((tn + tp)/(tn+tp+fp+fn))\n",
    "    if (tp + fp) == 0:\n",
    "      precisions.append(1)\n",
    "    else:\n",
    "      precisions.append(tp/(tp + fp))\n",
    "  accuracies2 = remove_upperclass(accuracies)\n",
    "  precisions2 = remove_upperclass(precisions)\n",
    "  return (sum(accuracies2)/len(accuracies2), sum(precisions2)/len(precisions2)), theta_mean\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w0B8Mde0O8NE"
   },
   "outputs": [],
   "source": [
    "def remove_upperclass(array):\n",
    "  new_array = []\n",
    "  for i in range(len(array)):\n",
    "    if i not in [0,1,10]:\n",
    "      new_array.append(array[i])\n",
    "  return new_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pFuNUUXoDrJA"
   },
   "outputs": [],
   "source": [
    "#def run_parallelized_test(datasets, lr_values, n_iter_values, random_seeds, num_cores):\n",
    "def run_parallelized_test(datasets, lr_values, n_iter_values,tolerances, num_cores):\n",
    "    processes = []\n",
    "    for dataset in datasets:\n",
    "      for lr in lr_values:\n",
    "          for n_iter in n_iter_values:\n",
    "            for T in tolerances:\n",
    "              #for seed in random_seeds:\n",
    "                  # Queue a process for each (n_samples, alpha, n_iter, seed) tuple\n",
    "              #processes.append([dataset, lr, n_iter, seed])\n",
    "              processes.append([dataset, lr, n_iter, T])\n",
    "    pool = Pool(processes=num_cores)\n",
    "    return pool.map(test_function, processes)\n",
    "\n",
    "def parallelize_predefined_tests(processes, num_cores):\n",
    "    pool = Pool(processes=num_cores)\n",
    "    return pool.map(test_function, processes)\n",
    "\n",
    "# Runs a single test for a (dataset, lr, n_iter) tuple\n",
    "def test_function(arguments):\n",
    "  dataset, lr, n_iter, T = arguments            \n",
    "  \n",
    "\n",
    "  # Log execution time for each test\n",
    "  time_start = timeit.default_timer()\n",
    "\n",
    "  print('running on the dataset ' + str(dataset) + ', lr=' + str(lr) + ', n_iter=' + str(n_iter) + '\\n')\n",
    "\n",
    "  # Generate the data based on the seed\n",
    "  data = load_dataset(dataset)                 \n",
    "\n",
    "  train, test = divide_train_test(data)\n",
    "\n",
    "  test_X,test_y = divide_Xy(test)\n",
    "\n",
    "  folds = divide_folds(train)\n",
    "  \n",
    "\n",
    "  # Generate random initial theta values based on the seed\n",
    "  #np.random.seed(seed)\n",
    "  #theta0 = np.random.rand(X.shape[1], len(np.unique(y)))\n",
    "  # Initialize theta0\n",
    "  #theta0 = np.zeros(X.shape[1])\n",
    "\n",
    "  # Run gradient descent\n",
    "  #theta_final, loss_history = gradient_descent(theta0, X, y, lr, n_iter)\n",
    "  metrics, theta_final = np.array(run_folds_class(folds,  n_iter, lr, T))                \n",
    "\n",
    "  # Compute elapsed time and accuracy\n",
    "  time_end = timeit.default_timer()\n",
    "  elapsed_time = time_end-time_start\n",
    "  #accuracy = compute_accuracy(theta_final, X, y)\n",
    "\n",
    "  #print('done! dataset=' + str(dataset) + ', lr=' + str(lr) + ', n_iter=' + str(n_iter) + ', seed=' + str(seed) + ', elapsed time=' + str(elapsed_time) + ', accuracy=' + str(accuracy) + '\\n')\n",
    "  print('done! dataset=' + str(dataset) + ', lr=' + str(lr) + ', n_iter=' + str(n_iter) + ', elapsed time=' + str(elapsed_time) + ', accuracy=' + str(metrics[0]) + ', precision=' + str(metrics[1]) +'\\n' )\n",
    "  \n",
    "  # Return the results\n",
    "  #return [(lr, n_iter, seed), elapsed_time, accuracy, log_l_history]\n",
    "  return [(dataset, lr, n_iter, T), elapsed_time, metrics[0], metrics[1], theta_final]             \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_IP_CsLbDrJA"
   },
   "outputs": [],
   "source": [
    "# Tests various possible numbers of samples, values of the learning rate and numbers of iterations\n",
    "\n",
    "# Initialize theta0\n",
    "#theta0 = np.zeros(white_x.shape[1])\n",
    "\n",
    "# Parameters used to run the tests\n",
    "datasets = ['winequality-white.csv', 'winequality-red.csv']        \n",
    "lr_values = [ 0.00001, 0.00002, 0.00005, 0.0001]\n",
    "n_iter_values = [500, 1000, 2000, 3000]\n",
    "tolerances = [0, 1]\n",
    "\n",
    "#datasets = [ 'winequality-red.csv']        \n",
    "#lr_values = [ 0.0001]\n",
    "#n_iter_values = [10]\n",
    "#tolerances = [0]\n",
    "\n",
    "sets = []\n",
    "# Server, 16 threads Francesco numero curr_set_index = 0\n",
    "sets.append([['winequality-red.csv', 2e-05, 3000, 1], ['winequality-red.csv', 5e-05, 3000, 1], ['winequality-red.csv', 0.0001, 3000, 1], ['winequality-white.csv', 2e-05, 3000, 0], ['winequality-white.csv', 5e-05, 3000, 0], ['winequality-white.csv', 0.0001, 3000, 0]])\n",
    "# Desktop, 12 threads Simone numero curr_set_index = 1\n",
    "sets.append([['winequality-red.csv', 0.0001, 4000, 1], ['winequality-red.csv', 0.0001, 4000, 1], ['winequality-red.csv', 0.0001, 3000, 0], ['winequality-white.csv', 1e-05, 3000, 0], ['winequality-red.csv', 2e-05, 3000, 0], ['winequality-red.csv', 0.0002, 2500, 1], ['winequality-red.csv', 0.0002, 2500, 1]])\n",
    "# Laptop, 8 threads Vito numero curr_set_index = 2\n",
    "sets.append([['winequality-white.csv', 1e-05, 500, 1], ['winequality-white.csv', 5e-06, 500, 1], ['winequality-white.csv', 75e-07, 500, 1], ['winequality-white.csv', 1e-05, 1000, 1], ['winequality-white.csv', 1e-05, 2000, 1], ['winequality-white.csv', 2e-05, 1000, 1], ['winequality-white.csv', 5e-06, 1000, 1], ['winequality-white.csv', 75e-07, 1000, 1], ['winequality-red.csv', 0.0001, 2000, 1], ['winequality-red.csv', 0.0002, 2000, 1], ['winequality-red.csv', 0.0005, 1500, 1], ['winequality-white.csv', 5e-05, 2000, 0], ['winequality-white.csv', 5e-06, 1000, 1], ['winequality-white.csv', 75e-07, 1000, 1], ['winequality-white.csv', 0.0003, 2000, 0], ['winequality-red.csv', 2e-05, 2000, 0], ['winequality-red.csv', 5e-05, 2000, 0], ['winequality-red.csv', 0.0002, 2000, 1], ['winequality-red.csv', 0.0005, 1500, 1]])\n",
    "sets.append([['winequality-white.csv', 0.001, 10, 0], ['winequality-red.csv', 0.001, 10, 0]])\n",
    "sets.append([['winequality-white.csv', 1e-05, 2000, 0], ['winequality-white.csv', 1e-05, 2000, 1]])\n",
    "sets.append([['winequality-red.csv', 0.0001, 10, 0], ['winequality-red.csv', 0.0001, 10, 1]])\n",
    "\n",
    "curr_set_index = -1\n",
    "\n",
    "# Times the duration of the batch\n",
    "time_start_test = timeit.default_timer()\n",
    "\n",
    "# Starts the tests\n",
    "#results = run_parallelized_test(datasets, lr_values, n_iter_values, tolerances, NUM_CORES)\n",
    "results = parallelize_predefined_tests(sets[curr_set_index], NUM_CORES)\n",
    "\n",
    "time_end_test = timeit.default_timer()\n",
    "test_elapsed_time = time_end_test-time_start_test\n",
    "print('test complete, elapsed time: ' + str(test_elapsed_time))\n",
    "\n",
    "print(results)\n",
    "\n",
    "comment='''# Only considers the last value of the loss function for the results\n",
    "output = []\n",
    "#for result in averaged_results:\n",
    "for result in results:\n",
    "  output.append([result[0], result[1], result[2], result[3]])\n",
    "print(output)'''\n",
    "\n",
    "results_file = open('classification_results_' + str(curr_set_index) + '.txt', 'w')\n",
    "for result in results:\n",
    "  results_file.write(str(result)+'\\n')\n",
    "results_file.close()\n",
    "# Run Gradient Ascent method\n",
    "#n_iter=1000\n",
    "#white_theta_final, white_loss_history = gradient_descent(theta0,white_x,white_y,lr=0.0000005,num_steps=n_iter)\n",
    "#red_theta_final, red_loss_history = gradient_descent(theta0,red_x,red_y,lr=0.0000005,num_steps=n_iter)\n",
    "#print(white_theta_final)\n",
    "#print(red_theta_final)\n",
    "#print(loss_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VKFqV_bTa7oC"
   },
   "outputs": [],
   "source": [
    "def to_regression(theta_final, X, y):\n",
    "  #print(theta_final)\n",
    "  preds = softmax(theta_final, X)\n",
    "  y_regr = []\n",
    "  for predicted_probabilities in preds:\n",
    "    somma = 0\n",
    "    divisore = sum(predicted_probabilities)\n",
    "    for i in range(len(preds[1])):\n",
    "      somma += i*predicted_probabilities[i]\n",
    "    y_regr.append(somma/divisore)\n",
    "  return y_regr\n",
    "\n",
    "y_regr = to_regression(results[-1][-1], red_test_X, red_test_y)\n",
    "y_regr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YgiMuxJGFtxw"
   },
   "outputs": [],
   "source": [
    "theta_final = results[-1][-1]\n",
    "y_pred = to_regression(results[-1][-1], red_test_X, red_test_y)\n",
    "y_true = red_test_y\n",
    "resultsmie = {}\n",
    "for T in tolerances:\n",
    "  resultsmie[T] = [[], []]\n",
    "for T in tolerances:\n",
    "  LAMIASOL = compute_accuracy(theta_final, dev_X, dev_y, T)\n",
    "  resultsmie[T][0].append(LAMIASOL)\n",
    "  classes = np.unique(y_true)\n",
    "  for i in classes:\n",
    "    new_y_pred = convertitor(y_pred, i, T)\n",
    "    new_y_true = convertitor(y_true, i, T)\n",
    "    cm = confusion_matrix(new_y_true, new_y_pred)\n",
    "    if (cm[1][1] + cm[0][1]) == 0:\n",
    "      precision = 0\n",
    "    else:\n",
    "      precision = cm[1][1] / (cm[1][1] + cm[0][1])\n",
    "    resultsmie[T][1].append(precision)\n",
    "averaged_accuracies = {}\n",
    "averaged_precisions = {}\n",
    "for T in tolerances:\n",
    "  averaged_accuracies[T] = sum(resultsmie[T][0]) / len(resultsmie[T][0])\n",
    "  averaged_precisions[T] = sum(resultsmie[T][1]) / len(resultsmie[T][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1FUcIYB0nxfz"
   },
   "outputs": [],
   "source": [
    "def convertitor(array, i, T):\n",
    "  new_array = []\n",
    "  for elem in array:\n",
    "    if elem-T <= i <= elem+T:\n",
    "      new_array.append(1)\n",
    "    else:\n",
    "      new_array.append(0)\n",
    "  return new_array\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jkdrji-hyBez"
   },
   "source": [
    "REC CURVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u_gY6nsUnxfz"
   },
   "outputs": [],
   "source": [
    "#DA LEVARE NEL MOMENTO IN CUI UNIAMO I DUE DOCUMENTI\n",
    "\n",
    "fig,ax = plt.subplots(num=2)\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.set_xlabel('T')\n",
    "_=ax.plot([x for x in averaged_accuracies.keys()],[y for y in averaged_accuracies.values()],'b.')\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Final_Project.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
